{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "933s33bIx8pi",
        "outputId": "59bb348c-9170-44fa-dc58-38ce72836b19"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "from torch import Tensor\n",
        "from torch.optim import SGD\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "tKpkSn6Hx8pn"
      },
      "outputs": [],
      "source": [
        "# train the model\n",
        "def train_model(train_dl, model, test_dl, gpu_mode, draw_plt, device):\n",
        "    # define the optimization\n",
        "    criterion = CrossEntropyLoss()\n",
        "    optimizer = SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "    # enumerate epochs\n",
        "    performance = []\n",
        "    for _ in tqdm(range(300)):\n",
        "        if draw_plt:\n",
        "            model.train()\n",
        "        # enumerate mini batches\n",
        "        for i, (inputs, targets) in enumerate(train_dl):\n",
        "            if gpu_mode:\n",
        "              inputs = inputs.to(device)\n",
        "              targets = targets.to(device)\n",
        "            targets_one_hot = F.one_hot(targets, num_classes=6)\n",
        "\n",
        "            targets_one_hot = targets_one_hot.view(-1, 6).to(torch.float)\n",
        "            # clear the gradients\n",
        "            optimizer.zero_grad()\n",
        "            # compute the model output\n",
        "            pred = model(inputs)\n",
        "            pred = pred.view(-1, 6)\n",
        "\n",
        "            # calculate loss\n",
        "            loss = criterion(pred, targets_one_hot)\n",
        "            # credit assignment\n",
        "            loss.backward()\n",
        "            # update model weights\n",
        "            optimizer.step()\n",
        "        \n",
        "        if draw_plt:\n",
        "            model.eval()\n",
        "            performance.append(evaluate_model(test_dl, model, gpu_mode))\n",
        "\n",
        "    return performance\n",
        "\n",
        "# evaluate the model\n",
        "def evaluate_model(test_dl, model, gpu_mode, device):\n",
        "    predictions, actuals = [], []\n",
        "    for i, (inputs, targets) in enumerate(test_dl):\n",
        "        # evaluate the model on the test set\n",
        "        if gpu_mode:\n",
        "          inputs = inputs.to(device)\n",
        "          targets = targets.to(device)\n",
        "        yhat = model(inputs)\n",
        "        # retrieve numpy array     \n",
        "        actual = targets.cpu().numpy()\n",
        "        actual = actual.reshape((-1, 1))\n",
        "        # round to class values\n",
        "        yhat = torch.argmax(yhat, dim=1).cpu().numpy()\n",
        "        yhat = yhat.reshape((-1, 1))\n",
        "        predictions.append(yhat)\n",
        "        actuals.append(actual)\n",
        "    predictions = np.vstack(predictions)\n",
        "    actuals = np.vstack(actuals)\n",
        "\n",
        "    return accuracy_score(actuals, predictions)   \n",
        "# make a class prediction for one row of data\n",
        "def predict(row, model):\n",
        "    # convert row to data\n",
        "    row = Tensor([row])\n",
        "    # make prediction\n",
        "    pred = model(row)\n",
        "    # retrieve numpy array\n",
        "    pred = np.argmax(pred.detach().numpy())\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IF21Busdx8pl"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, train_X, train_y):\n",
        "        self.X = torch.from_numpy(train_X)\n",
        "        self.labels = torch.from_numpy(train_y.astype(int)).view(-1, 1) - 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.labels[index]\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.input_layer = nn.Linear(48 * 48 * 3, 4096)\n",
        "        self.output_layer = nn.Linear(4096, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 48 * 48 * 3)\n",
        "        x = self.input_layer(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.output_layer(x)\n",
        "        x = torch.softmax(x, dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tAyLlrUMkOGn"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=3,\n",
        "                out_channels=16,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=2,\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, 3, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.out = nn.Linear(32 * 13 * 13, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.out(x)\n",
        "        x = torch.softmax(x, dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oUjDRPMBS-7q"
      },
      "outputs": [],
      "source": [
        "def generate_confusion_matrix(cnf_matrix, classes, normalize=False, title='Confusion matrix'):\n",
        "    if normalize:\n",
        "        cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    plt.imshow(cnf_matrix, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cnf_matrix.max() / 2.\n",
        "\n",
        "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
        "        plt.text(j, i, format(cnf_matrix[i, j], fmt), horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "    return cnf_matrix\n",
        "\n",
        "def plot_confusion_matrix(predictions, actuals):\n",
        "    class_name=[0, 1, 2, 3, 4, 5]\n",
        "    cnf_matrix = confusion_matrix(actuals, predictions)\n",
        "    np.set_printoptions(precision=2)\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    plt.figure()\n",
        "    generate_confusion_matrix(cnf_matrix, classes=class_name, title='Confusion matrix, without normalization')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot normalized confusion matrix\n",
        "    plt.figure()\n",
        "    generate_confusion_matrix(cnf_matrix, classes=class_name, normalize=True, title='Normalized confusion matrix')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pFy2QV93Nzfe"
      },
      "outputs": [],
      "source": [
        "def print_report(acc, actuals, predictions):\n",
        "    print('Accuracy: %s' % acc)\n",
        "    print()\n",
        "    plot_confusion_matrix(predictions, actuals)\n",
        "    print()\n",
        "    print('Confusion Matrix:')\n",
        "    print(confusion_matrix(actuals, predictions))\n",
        "    print()\n",
        "    print('Classification Report:')\n",
        "    print(classification_report(actuals, predictions, zero_division=1))\n",
        "\n",
        "def evaluate_report(test_dl, model, gpu_mode, device):\n",
        "    predictions, actuals = [], []\n",
        "    for i, (inputs, targets) in enumerate(test_dl):\n",
        "        # evaluate the model on the test set\n",
        "        if gpu_mode:\n",
        "          inputs = inputs.to(device)\n",
        "          targets = targets.to(device)\n",
        "        yhat = model(inputs)\n",
        "        # retrieve numpy array\n",
        "        \n",
        "        actual = targets.cpu().numpy()\n",
        "        actual = actual.reshape((-1, 1))\n",
        "        # round to class values\n",
        "        yhat = torch.argmax(yhat, dim=1).cpu().numpy()\n",
        "        yhat = yhat.reshape((-1, 1))\n",
        "\n",
        "        predictions.append(yhat)\n",
        "        actuals.append(actual)\n",
        "\n",
        "    predictions = np.vstack(predictions)\n",
        "    actuals = np.vstack(actuals)\n",
        "    acc = accuracy_score(actuals, predictions) \n",
        "\n",
        "    print_report(acc, actuals, predictions)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2o-G9UT_x8pm"
      },
      "outputs": [],
      "source": [
        "is_colab = False\n",
        "draw_plt = True\n",
        "gpu_mode = True\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "if torch.cuda.is_available(): \n",
        "    dev = \"cuda\" \n",
        "else: \n",
        "    dev = \"cpu\"\n",
        "device = torch.device(dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "HdM5fJ61Hf2l"
      },
      "outputs": [],
      "source": [
        "part = 'part1'\n",
        "dataset_path = os.path.join('datasets', part)\n",
        "if is_colab:\n",
        "    dataset_path = os.path.join('/content/drive/MyDrive/AI_hw/hw1', dataset_path)\n",
        "    \n",
        "train_X_path  = os.path.join(dataset_path, 'train_X.npy')\n",
        "train_y_path  = os.path.join(dataset_path, 'train_y.npy')\n",
        "test_X_path = os.path.join(dataset_path, 'test_X.npy')\n",
        "test_X_path = os.path.join(dataset_path, 'test_y.npy')\n",
        "\n",
        "train_X = np.load(os.path.join(dataset_path, 'train_X.npy'))\n",
        "train_y = np.load(os.path.join(dataset_path, 'train_y.npy'))\n",
        "test_X = np.load(os.path.join(dataset_path, 'test_X.npy'))\n",
        "test_y = np.load(os.path.join(dataset_path, 'test_y.npy'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "vIuHjzeGc_IB"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(train_X, train_y)\n",
        "test_dataset = Dataset(test_X, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KVQU5i9NIvU4",
        "outputId": "3acd084a-1f4e-4f09-8586-25fa24c45899"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [2],\n",
            "        [2],\n",
            "        [0],\n",
            "        [3],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [4],\n",
            "        [1],\n",
            "        [5],\n",
            "        [3],\n",
            "        [5],\n",
            "        [4],\n",
            "        [4],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [3],\n",
            "        [0],\n",
            "        [4],\n",
            "        [3],\n",
            "        [2],\n",
            "        [0],\n",
            "        [4],\n",
            "        [2],\n",
            "        [0],\n",
            "        [4],\n",
            "        [0],\n",
            "        [4],\n",
            "        [5],\n",
            "        [0],\n",
            "        [2],\n",
            "        [3],\n",
            "        [3],\n",
            "        [4],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [2],\n",
            "        [1],\n",
            "        [0],\n",
            "        [3],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [4],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [2],\n",
            "        [0],\n",
            "        [4],\n",
            "        [2]], device='cuda:0', dtype=torch.int32)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "one_hot is only applicable to index tensor.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[37], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mif\u001b[39;00m gpu_mode:\n\u001b[0;32m     18\u001b[0m     model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 20\u001b[0m performance_per_epoch \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(train_model(trainloader, model, testloader, gpu_mode, draw_plt, device))\n\u001b[0;32m     23\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     24\u001b[0m     acc \u001b[39m=\u001b[39m evaluate_report(testloader, model, gpu_mode, device)\n",
            "Cell \u001b[1;32mIn[29], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(train_dl, model, test_dl, gpu_mode, draw_plt, device)\u001b[0m\n\u001b[0;32m     15\u001b[0m   targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(targets)\n\u001b[1;32m---> 17\u001b[0m targets_one_hot \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mone_hot(targets, num_classes\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m)\n\u001b[0;32m     19\u001b[0m targets_one_hot \u001b[39m=\u001b[39m targets_one_hot\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m6\u001b[39m)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m     20\u001b[0m \u001b[39m# clear the gradients\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: one_hot is only applicable to index tensor."
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_indices = list(range(len(train_X)))\n",
        "test_indices = list(range(len(test_X)))\n",
        "\n",
        "train_subsampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "test_subsampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_subsampler)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, sampler=test_subsampler)\n",
        "\n",
        "CNN = CNN()\n",
        "MLP = MLP()\n",
        "models = [(MLP, 'MLP'), (CNN, 'CNN')]\n",
        "plt.cla()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "for model, model_name in models:\n",
        "    if gpu_mode:\n",
        "        model.to(device)\n",
        "    performance_per_epoch = np.array(train_model(trainloader, model, testloader, gpu_mode, draw_plt, device))\n",
        "    with torch.no_grad():\n",
        "        acc = evaluate_report(testloader, model, gpu_mode, device)\n",
        "\n",
        "    if draw_plt:\n",
        "        plt.plot(performance_per_epoch, label = model_name)\n",
        "        plt.legend(loc = 'lower right')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
